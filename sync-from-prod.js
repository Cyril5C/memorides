#!/usr/bin/env node

/**
 * Script de synchronisation depuis la production
 * - T√©l√©charge le backup depuis l'API de production
 * - √âcrase la base de donn√©es locale
 * - √âcrase les fichiers GPX locaux
 * - NE TOUCHE PAS aux photos locales
 */

const https = require('https');
const fs = require('fs').promises;
const path = require('path');
const { execSync } = require('child_process');

const PROD_URL = 'https://memorides-production.up.railway.app';
const EXPORT_DIR = path.join(__dirname, 'exports');
const TIMESTAMP = new Date().toISOString().split('T')[0];
const BACKUP_ZIP = path.join(EXPORT_DIR, `prod-sync-${TIMESTAMP}.zip`);
const BACKUP_DIR = path.join(EXPORT_DIR, `prod-sync-${TIMESTAMP}`);
const DB_PATH = path.join(__dirname, 'prisma', 'prisma', 'dev.db');
const GPX_DIR = path.join(__dirname, 'uploads', 'gpx');

async function ensureDir(dir) {
    try {
        await fs.mkdir(dir, { recursive: true });
    } catch (error) {
        if (error.code !== 'EEXIST') throw error;
    }
}

async function downloadFile(url, dest) {
    return new Promise((resolve, reject) => {
        const file = require('fs').createWriteStream(dest);
        https.get(url, (response) => {
            if (response.statusCode !== 200) {
                reject(new Error(`Failed to download: ${response.statusCode}`));
                return;
            }

            const totalSize = parseInt(response.headers['content-length'], 10);
            let downloadedSize = 0;

            response.on('data', (chunk) => {
                downloadedSize += chunk.length;
                const percent = ((downloadedSize / totalSize) * 100).toFixed(1);
                process.stdout.write(`\r   Progression: ${percent}% (${(downloadedSize / 1024 / 1024).toFixed(2)} MB / ${(totalSize / 1024 / 1024).toFixed(2)} MB)`);
            });

            response.pipe(file);
            file.on('finish', () => {
                file.close();
                console.log('\n');
                resolve();
            });
        }).on('error', (err) => {
            fs.unlink(dest);
            reject(err);
        });
    });
}

async function syncFromProd() {
    console.log('\n========================================');
    console.log('üîÑ SYNCHRONISATION DEPUIS LA PRODUCTION');
    console.log('========================================\n');

    try {
        // 1. Cr√©er le dossier d'export
        console.log('üìÅ Cr√©ation du dossier d\'export...');
        await ensureDir(EXPORT_DIR);

        // 2. T√©l√©charger le backup depuis la production
        console.log('\nüì• T√©l√©chargement du backup depuis la production...');
        console.log(`   URL: ${PROD_URL}/api/export/backup`);
        await downloadFile(`${PROD_URL}/api/export/backup`, BACKUP_ZIP);

        const stats = await fs.stat(BACKUP_ZIP);
        console.log(`‚úÖ Backup t√©l√©charg√©: ${(stats.size / 1024 / 1024).toFixed(2)} MB`);

        // 3. Extraire l'archive
        console.log('\nüì¶ Extraction de l\'archive...');
        await ensureDir(BACKUP_DIR);
        execSync(`unzip -o "${BACKUP_ZIP}" -d "${BACKUP_DIR}"`, { stdio: 'inherit' });
        console.log('‚úÖ Archive extraite');

        // 4. V√©rifier les fichiers extraits
        const dbSqlPath = path.join(BACKUP_DIR, 'database', 'backup.sql');
        const gpxBackupDir = path.join(BACKUP_DIR, 'gpx');

        const dbSqlExists = await fs.access(dbSqlPath).then(() => true).catch(() => false);
        const gpxDirExists = await fs.access(gpxBackupDir).then(() => true).catch(() => false);

        if (!dbSqlExists) {
            throw new Error('Fichier database/backup.sql introuvable dans le backup');
        }

        // 5. Importer la base de donn√©es
        console.log('\nüóÑÔ∏è  Import de la base de donn√©es...');
        console.log(`   Cible: ${DB_PATH}`);

        // V√©rifier que la base existe
        const dbExists = await fs.access(DB_PATH).then(() => true).catch(() => false);
        if (!dbExists) {
            throw new Error('Base de donn√©es locale introuvable. Lancez d\'abord le serveur local pour cr√©er la base.');
        }

        execSync(`sqlite3 "${DB_PATH}" < "${dbSqlPath}"`, { stdio: 'inherit' });

        // V√©rifier l'import
        const trackCount = execSync(`sqlite3 "${DB_PATH}" "SELECT COUNT(*) FROM Track;"`, { encoding: 'utf8' }).trim();
        console.log(`‚úÖ Base de donn√©es import√©e: ${trackCount} traces`);

        // 6. Copier les fichiers GPX
        console.log('\nüìÑ Synchronisation des fichiers GPX...');

        if (gpxDirExists) {
            // Vider le dossier GPX local
            console.log('   Suppression des GPX locaux...');
            await fs.rm(GPX_DIR, { recursive: true, force: true });
            await ensureDir(GPX_DIR);

            // Copier les nouveaux GPX
            console.log('   Copie des GPX de production...');
            const gpxFiles = await fs.readdir(gpxBackupDir);
            for (const file of gpxFiles) {
                await fs.copyFile(
                    path.join(gpxBackupDir, file),
                    path.join(GPX_DIR, file)
                );
            }
            console.log(`‚úÖ ${gpxFiles.length} fichiers GPX synchronis√©s`);
        } else {
            console.log('‚ö†Ô∏è  Aucun fichier GPX dans le backup');
        }

        // 7. Nettoyer
        console.log('\nüßπ Nettoyage...');
        await fs.rm(BACKUP_ZIP);
        await fs.rm(BACKUP_DIR, { recursive: true });
        console.log('‚úÖ Fichiers temporaires supprim√©s');

        console.log('\n========================================');
        console.log('‚úÖ SYNCHRONISATION TERMIN√âE !');
        console.log('========================================\n');
        console.log('üìä Base de donn√©es: √©cras√©e');
        console.log('üìÑ Fichiers GPX: √©cras√©s');
        console.log('üì∏ Photos: conserv√©es (non modifi√©es)\n');

    } catch (error) {
        console.error('\n‚ùå Erreur lors de la synchronisation:', error.message);
        process.exit(1);
    }
}

syncFromProd();
